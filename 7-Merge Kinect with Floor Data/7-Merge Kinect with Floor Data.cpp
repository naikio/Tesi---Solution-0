#include "stdafx.h"

#define NOMINMAX
#define _WINSOCK_DEPRECATED_NO_WARNINGS

#define BGD_SUBTRACTION true
#define CROP_BOX_FILTERING true
#define GET_PLANE_COEFFICIENTS false //used to search for floor plane coefficients (useful to retrieve plane coefficients the 1st time)
#define PLANAR_PROJECTION false
#define PCL_VISUALIZER

#include <opencv2\opencv.hpp>

#include <Windows.h>

#include <Kinect.h>
#include "acquisitionkinect2.h"

#include <pcl\visualization\cloud_viewer.h>
#include <pcl\visualization\pcl_visualizer.h>
#include <pcl/filters/crop_box.h>
#include <pcl/sample_consensus/method_types.h>
#include <pcl/sample_consensus/model_types.h>
#include <pcl/segmentation/sac_segmentation.h>
#include <pcl/filters/project_inliers.h>

#include<winsock2.h>
#pragma comment(lib,"ws2_32.lib") //Winsock Library
#include <boost/thread.hpp>
#include <boost/chrono.hpp>

using namespace cv;
using namespace std;
using namespace pcl;

void contrastStretching(Mat mat);

int _tmain(int argc, _TCHAR* argv[])
{
	// OPENCV stuff
	BackgroundSubtractorMOG2 pMOG2; //MOG2 Background subtractor
	Mat fgMaskMOG2; //fg mask generated by MOG2 method
	Mat colorMat, depthMat;	//color and depth images from Kinect

	//Custom Kinect Acquisition
	AcquisitionKinect2 acq = AcquisitionKinect2();
	FrameSet kinectFrame; //Acquisition frame: contains both depth and rgb images

	//Create PointCloud (plus its ColorHandler) and add it to the Visualizer
	PointCloud<PointXYZRGB>::Ptr pointCloud(new PointCloud<PointXYZRGB>());

	#ifdef PCL_VISUALIZER //Visualizer init
		//Init PCL Visualizer
		boost::shared_ptr<visualization::PCLVisualizer> PCLviewer(new visualization::PCLVisualizer("3D Viewer"));
		PCLviewer->setBackgroundColor(0, 0, 0);
		PCLviewer->addCoordinateSystem(1);
		PCLviewer->initCameraParameters();

		//Create PointCloud's ColorHandler and add everything to the Visualizer
		visualization::PointCloudColorHandlerRGBField<PointXYZRGB> rgb(pointCloud);
		PCLviewer->addPointCloud<PointXYZRGB>(pointCloud, rgb, "Kinect Depth Cloud");
		PCLviewer->setPointCloudRenderingProperties(pcl::visualization::PCL_VISUALIZER_POINT_SIZE, 3, "Kinect Depth Cloud");
	#endif

	//Socket opening and connection
	WSADATA wsa;
	SOCKET s;
	struct sockaddr_in server;
	char *message, server_reply[2000];
	int recv_size;
	int consecutiveWrongFrames = 0;

	cout << "\nInitialising Winsock...";
	if (WSAStartup(MAKEWORD(2, 2), &wsa) != 0)
	{
		cout << "Failed. Error Code : %d", WSAGetLastError();
		return 1;
	}

	cout << "Initialised.\n";

	//Create a socket
	if ((s = socket(AF_INET, SOCK_STREAM, 0)) == INVALID_SOCKET)
	{
		cout << "Could not create socket : %d", WSAGetLastError();
	}
	cout << "Socket created.\n";
	//Socket parameters
	server.sin_addr.s_addr = inet_addr("127.0.0.1");
	server.sin_family = AF_INET;
	server.sin_port = htons(4444);

	//Connect to remote server
	if (connect(s, (struct sockaddr *)&server, sizeof(server)) < 0)
	{
		puts("connect error");
		return 1;
	}
	puts("Connected");

	// Main loop: kinect image processing
	while (!GetAsyncKeyState(VK_ESCAPE)){
		//Socket request and floor image retrieval
		message = "f"; //Request: "f" asks for a frame
		if (send(s, message, strlen(message), 0) < 0)
		{
			puts("Send failed");
			return 2;
		}
		puts("Data Sent\n");

		//Receive a reply from the server
		if ((recv_size = recv(s, server_reply, 2000, 0)) == SOCKET_ERROR)
		{
			puts("recv failed");
		}

		puts("Reply received\n");

		//Add a NULL terminating character to make it a proper string before printing
		server_reply[recv_size] = '\0';
		puts(server_reply);


		//Check received data

		// 1st byte: 0xFD
		// 2nd, 3rd: w, h of the image
		// 
		// data: w*h bytes, one for each pixels
		//
		// checksum: 0x0 for now
		// final byte: 0xFF
		
		int k = 0; //used to iterate over data
		// 1: 0xFD
		if (server_reply[k++] != (char)0xFD){
			cerr << "Error: wrong header" << endl;
			consecutiveWrongFrames++;
			if (consecutiveWrongFrames > 10){
				cerr << "Too many wrong frames" << endl;
				return 1;
			}
			continue;
		}

		// 2,3: w, h
		int floorViewerWidth = (int)server_reply[k++];
		int floorViewerHeight = (int)server_reply[k++];
		Mat1b floor(floorViewerHeight, floorViewerWidth); //floor image has 32x24 px
		
		// image data
		for (int r = 0; r < floor.rows; r++){
			for (int c = 0; c < floor.cols; c++){
				floor(r, c) = (uchar)server_reply[k++];
			}
		}

		// last byte
		if (server_reply[k++] != (char)0x0){
			cerr << "Error: wrong checksum" << endl;
			consecutiveWrongFrames++;
			if (consecutiveWrongFrames > 10){
				cerr << "Too many wrong frames" << endl;
				return 1;
			}
			continue;
		}
		if (server_reply[k] == (char)0xFF){
			consecutiveWrongFrames = 0;
			cout << "Successful data verification" << endl;
		}


		resize(floor, floor, Size(420, 300), 0, 0, cv::INTER_CUBIC);
		for (int r = 0; r < floor.rows;r++){
			for (int c = 0; c < floor.cols;c++){
				if ((r % 60) == 0 || (c % 60) == 0){
					floor(r, c) = 255;
				}
			}
		}

		imshow("Floor", floor);

		//Get coordinate mapper to map colors into depth image, and readers to read data from RGB and Depth cameras
		ICoordinateMapper* coordinateMapper = acq.GetCoordinateMapper();
		IColorFrameReader* colorReader = acq.GetColorReader();
		IDepthFrameReader* depthReader = acq.GetDepthReader();

		// Kinect v2 Depth image's resolution is 512x424 pixels
		int depthWidth = 512;
		int depthHeight = 424;
		// To Reserve Depth Frame Buffer
		std::vector<UINT16> depthBuffer(depthWidth * depthHeight);
		// Kinect v2 Color image's resolution is FullHD (1920x1080)
		int colorWidth = 1920;
		int colorHeight = 1080;
		// To Reserve Color Frame Buffer
		std::vector<RGBQUAD> colorBuffer(colorWidth * colorHeight);
		//Buffers contain raw data from the 2 images

		/////////////////////////////
		////////// KINECT ACQUISITION
		/////////////////////////////

		// Acquire Latest Color Frame
		IColorFrame* pColorFrame = nullptr;
		HRESULT hResult = S_OK;
		hResult = colorReader->AcquireLatestFrame(&pColorFrame);
		if (SUCCEEDED(hResult)){
			// Retrieved Color Data
			hResult = pColorFrame->CopyConvertedFrameDataToArray(colorBuffer.size() * sizeof(RGBQUAD), reinterpret_cast<BYTE*>(&colorBuffer[0]), ColorImageFormat::ColorImageFormat_Bgra);
			if (FAILED(hResult)){
				std::cerr << "Error : IColorFrame::CopyConvertedFrameDataToArray()" << std::endl;
			}
		}
		else{ continue; }
		if (SUCCEEDED(hResult))
		{
			// conversion to OPENCV Mat
			Mat ris2 = Mat(colorHeight, colorWidth, CV_8UC4, &colorBuffer[0], Mat::AUTO_STEP).clone();
			cvtColor(ris2, ris2, CV_BGRA2BGR);
			colorMat = ris2.clone();
			//imshow("", colorMat);
			//waitKey(30);
		}
		SafeRelease(pColorFrame);

		// Acquire Latest Depth Frame
		IDepthFrame* pDepthFrame = nullptr;
		hResult = depthReader->AcquireLatestFrame(&pDepthFrame);
		if (SUCCEEDED(hResult)){
			// Retrieved Depth Data
			hResult = pDepthFrame->CopyFrameDataToArray(depthBuffer.size(), &depthBuffer[0]);
			if (FAILED(hResult)){
				std::cerr << "Error : IDepthFrame::CopyFrameDataToArray()" << std::endl;
			}
		}
		else{ continue; }
		if (SUCCEEDED(hResult))
		{
			// conversion to OPENCV Mat
			UINT16* depthArray = new UINT16[depthHeight*depthWidth];
			copy(depthBuffer.begin(), depthBuffer.end(), depthArray);

			Mat ris2 = Mat(depthHeight, depthWidth, CV_16UC1, depthArray, Mat::AUTO_STEP).clone();
			Mat3b risDef(depthHeight, depthWidth);

			int x, y;
			for (y = 0; y<depthHeight; y++)
				for (x = 0; x<depthWidth; x++){
					risDef(y, x)[0] = (ris2.at<UINT16>(y, x) - 500) / 8;
					risDef(y, x)[1] = (ris2.at<UINT16>(y, x) - 500) / 8;
					risDef(y, x)[2] = (ris2.at<UINT16>(y, x) - 500) / 8;
				}

			depthMat = ris2.clone();
			//imshow("", depthMat);
			//waitKey(30);
			delete[] depthArray;
		}
		SafeRelease(pDepthFrame);

		/////////////////////////////
		////////////// IMG PROCESSING
		/////////////////////////////

		// BGD SUBTRACTION
		// Lets change some MOG2 parameters
		pMOG2.set("varThresholdGen", 625.0);
		pMOG2.set("backgroundRatio", 0.4);

		//store depthImage filtered after BGD Subtraction
		// initialized with depthBuffer, so that if BGD_SUBTRACTION is set to False, it contains original depth image
		std::vector<UINT16> foregroundDepthBuffer(depthBuffer); 
		
		//Update the background model
		if (BGD_SUBTRACTION){
			pMOG2(depthMat, fgMaskMOG2);

			// Morphology: OPEN
			int morph_size = 2;
			Mat element = getStructuringElement(MORPH_ELLIPSE, Size(4 * morph_size + 1, 2 * morph_size + 1), Point(morph_size, morph_size));
			morphologyEx(fgMaskMOG2, fgMaskMOG2, MORPH_OPEN, element);

			Mat foregroundDepthMat; //where we store the final result
			depthMat.copyTo(foregroundDepthMat, fgMaskMOG2); //filtering the original depthMat through bgdSUB mask to obtain final result

			//we have to revert to a vector to use it in a pointcloud
			foregroundDepthBuffer.clear(); //clear content (original depth image (see initialization))
			foregroundDepthBuffer.assign((UINT16*)(foregroundDepthMat.datastart), (UINT16*)(foregroundDepthMat.dataend));
			//(debug)
			//imshow("Original Depth", depthMat);
			//imshow("foreground Depth Mat", foregroundDepthMat);
			//waitKey(30);
		}

		// Set Point Cloud Parameters
		pointCloud->width = static_cast<uint32_t>(depthWidth);
		pointCloud->height = static_cast<uint32_t>(depthHeight);
		pointCloud->is_dense = false;
		// Fill point cloud with points
		for (int y = 0; y < depthHeight; y++){
			for (int x = 0; x < depthWidth; x++){
				PointXYZRGB point;

				DepthSpacePoint depthSpacePoint = { static_cast<float>(x), static_cast<float>(y) };
				UINT16 depth = foregroundDepthBuffer[y * depthWidth + x];
				//if depth is 0, this points belong to the background: we dont need them
				if (depth == 0)
					continue;

				// Coordinate Mapping Depth to Color Space, and Setting PointCloud RGB
				ColorSpacePoint colorSpacePoint = { 0.0f, 0.0f };
				coordinateMapper->MapDepthPointToColorSpace(depthSpacePoint, depth, &colorSpacePoint);
				int colorX = static_cast<int>(std::floor(colorSpacePoint.X + 0.5f));
				int colorY = static_cast<int>(std::floor(colorSpacePoint.Y + 0.5f));
				if ((0 <= colorX) && (colorX < colorWidth) && (0 <= colorY) && (colorY < colorHeight)){
					RGBQUAD color = colorBuffer[colorY * colorWidth + colorX];
					point.b = color.rgbBlue;
					point.g = color.rgbGreen;
					point.r = color.rgbRed;
				}

				// Coordinate Mapping Depth to Camera Space, and Setting PointCloud XYZ
				CameraSpacePoint cameraSpacePoint = { 0.0f, 0.0f, 0.0f };
				coordinateMapper->MapDepthPointToCameraSpace(depthSpacePoint, depth, &cameraSpacePoint);
				if ((0 <= colorX) && (colorX < colorWidth) && (0 <= colorY) && (colorY < colorHeight)){
					point.x = cameraSpacePoint.X;
					point.y = cameraSpacePoint.Y;
					point.z = cameraSpacePoint.Z;
				}

				pointCloud->push_back(point);

			}
		}


		// Free memory
		vector<UINT16>().swap(depthBuffer);
		vector<UINT16>().swap(foregroundDepthBuffer);

		// Crop box: min and max points are corners of the parallelepiped that will be used as a filter
		Eigen::Vector4f minPoint;
		minPoint[0] = -1.8;  // define minimum point x (R)
		minPoint[1] = -1.20;  // define minimum point y (G)
		minPoint[2] = 0;  // define minimum point z (B)
		Eigen::Vector4f maxPoint;
		maxPoint[0] = 3.65;  // define max point x 
		maxPoint[1] = 1.56;  // define max point y 
		maxPoint[2] = 2.96;  // define max point z 

		if (CROP_BOX_FILTERING){
			CropBox<PointXYZRGB> cropFilter;
			PointCloud<PointXYZRGB>::Ptr pointCloud2(new PointCloud<PointXYZRGB>());
			*pointCloud2 = *pointCloud;
			cropFilter.setInputCloud(pointCloud2);
			cropFilter.setMin(minPoint);
			cropFilter.setMax(maxPoint);
			cropFilter.filter(*pointCloud);
			pointCloud2->clear();
		}




		///////////////////////////
		/////////// Plane Detection
		///////////////////////////

		//GET_PLANE_COEFFICIENTS variable is use to get coefficients of the floor plane (printed out to the command line)
		pcl::ModelCoefficients::Ptr coefficients(new pcl::ModelCoefficients);
		if (GET_PLANE_COEFFICIENTS){
			pcl::PointIndices::Ptr inliers(new pcl::PointIndices);
			// Create the segmentation object
			SACSegmentation<PointXYZRGB> seg;
			// Optional
			seg.setOptimizeCoefficients(true);
			// Mandatory
			seg.setModelType(SACMODEL_PLANE);
			seg.setMethodType(SAC_RANSAC);
			seg.setDistanceThreshold(0.01);
			seg.setProbability(0.9999);
			seg.setMaxIterations(300);

			seg.setInputCloud(pointCloud);
			seg.segment(*inliers, *coefficients);

			cout << "* * * New Iteration * * *" << endl;
			cout << "Model coefficients: " << coefficients->values[0] << " "
				<< coefficients->values[1] << " "
				<< coefficients->values[2] << " "
				<< coefficients->values[3] << endl;
		}
		else{ //If variable is false, we set the coefficients manually and use them for the projection
			coefficients->values.resize(4);
			coefficients->values[0] = -0.00424754;
			coefficients->values[1] = -0.981478;
			coefficients->values[2] = 0.19153;
			coefficients->values[3] = -1.11181;
		}

		// Planar Projection
#ifdef PCL_VISUALIZER
		PCLviewer->removeShape("Projection plane");
#endif
		//PCLviewer->addPlane(*coefficients, 0, 0, 1.7, "Projection plane"); //show projection plane
		if (PLANAR_PROJECTION){
			ProjectInliers<pcl::PointXYZRGB> proj;
			proj.setModelType(pcl::SACMODEL_PLANE);
			proj.setInputCloud(pointCloud);
			proj.setModelCoefficients(coefficients);
			proj.filter(*pointCloud);
		}
		
		Mat floorProjection(300,420, CV_16UC1, Scalar(0,0,0));

		// EIGEN TRANSFORM
		// Rotation to move origin on the floor and align XY plane to it
		Eigen::Affine3f transformation;
		getTransformationFromTwoUnitVectorsAndOrigin(	Eigen::Vector3f(0, -coefficients->values[3] / coefficients->values[1], 0), // Y direction (intersection with XZ plane)
														Eigen::Vector3f(-coefficients->values[0], coefficients->values[1], coefficients->values[2]), // Z direction (normal vector to the floor plane)
														Eigen::Vector3f(0.893489282, -0.618893445, 2.42300010), // Origin
														transformation
													);
		transformPointCloud(*pointCloud, *pointCloud, transformation);

		//At this point, we fill the Mat to revert to a grayscale image of the floor projection
		// offsets: translation from the Origin point
		float x_offset = -0.55;
		float y_offset = -0.75;
		float x_end = x_offset + 4.20; //floor is 4.20 x 3.00 m
		float y_end = y_offset + 3.00;
		//End point (low-right point of the image)
		for (PointCloud<PointXYZRGB>::iterator it = pointCloud->points.begin(); it < pointCloud->points.end(); it++){
			if ((it->x > x_offset) && (it->y > y_offset) && (it->x < x_end) && (it->y < y_end) && ((it->y * 100)<depthMat.rows) && ((it->x * 100)<depthMat.cols)){
				//starting from 0 (black) we increment the value for each point projected on a given floor point (same(x,y))
				// *X multiplication is needed because unit coordinates are meters (*100 = cm, for example) 
				floorProjection.at<unsigned short int>((int)((it->y - y_offset) * 100), (int)((it->x - x_offset) * 100))++;
			}
		}

		//reconversion to Uchar for better visualization
		floorProjection.convertTo(floorProjection, CV_8UC1);
		contrastStretching(floorProjection);

		Mat3b mergedChannels(300, 420, Vec3b(0, 0, 0));

		for (int r = 0; r < mergedChannels.rows; r++){
			for (int c = 0; c < mergedChannels.cols; c++){
				// Red channel : floor projection
				// Green channel: florimage data
				mergedChannels(r, c)[2] = (char)floorProjection.at<uchar>(r, c);
				mergedChannels(r, c)[1] = (char)floor.at<uchar>(r, c);
			}
		}

		//Show results
		resize(mergedChannels, mergedChannels, Size(), 3, 3, CV_INTER_CUBIC);
		imshow("Floor Projection", floorProjection);
		imshow("Merged Channels", mergedChannels);
		waitKey(25);
		
#ifdef PCL_VISUALIZER
		// PCL Visualizer
		PCLviewer->updatePointCloud<PointXYZRGB>(pointCloud, rgb, "Kinect Depth Cloud");
		PCLviewer->spinOnce();
		boost::this_thread::sleep(boost::posix_time::microseconds(10000));
#endif

		pointCloud->clear();
	}
	// End Processing
	return 0;
}



string exec(const char* cmd) {
	char buffer[128];
	std::string result = "";
	std::shared_ptr<FILE> pipe(_popen(cmd, "r"), _pclose);
	if (!pipe) throw std::runtime_error("popen() failed!");
	while (!feof(pipe.get())) {
		if (fgets(buffer, 128, pipe.get()) != NULL)
			result += buffer;
	}
	return result;
}

void contrastStretching(Mat mat){
	//Contrast stretching - ugly
	int min = 0;
	int max = 0;
	for (int r = 0; r < mat.rows; ++r) {
		for (int c = 0; c < mat.cols; ++c) {
			if (mat.at<uchar>(r, c) > max)
				max = mat.at<uchar>(r, c);
		}
	}
	//cout << "Max = " << max << endl;

	for (int r = 0; r < mat.rows; ++r) {
		for (int c = 0; c < mat.cols; ++c) {
			//increase pixel for each pointcloud's point projected on (c,r)
			mat.at<uchar>(r, c) = (mat.at<uchar>(r, c) - min) * 255 / std::max(1, (max - min));
		}
	}
}