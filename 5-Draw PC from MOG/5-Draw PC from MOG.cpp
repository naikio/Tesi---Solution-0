#include "stdafx.h"

#define NOMINMAX

#include <opencv2\opencv.hpp>

#include <Windows.h>

#include <Kinect.h>
#include "acquisitionkinect2.h"

#include <pcl\visualization\cloud_viewer.h>
#include <pcl\visualization\pcl_visualizer.h>
#include <pcl/filters/crop_box.h>
//#include <pcl/io/image_depth.h>

using namespace cv;
using namespace std;
using namespace pcl;

int _tmain(int argc, _TCHAR* argv[])
{
	// OPENCV stuff
	BackgroundSubtractorMOG2 pMOG2; //MOG2 Background subtractor
	Mat fgMaskMOG2; //fg mask fg mask generated by MOG2 method
	Mat colorMat, depthMat;	//color and depth images from Kinect
	

	//Custom Kinect Acquisition
	AcquisitionKinect2 acq = AcquisitionKinect2();
	FrameSet kinectFrame; //Acquisition frame: contains both depth and rgb images

	// Create Cloud Viewer
	visualization::CloudViewer viewer("Point Cloud Viewer");

	while (!viewer.wasStopped()){

		//Get coordinate mapper to map colors into depth image, and readers to read data
		ICoordinateMapper* coordinateMapper = acq.GetCoordinateMapper();
		IColorFrameReader* colorReader = acq.GetColorReader();
		IDepthFrameReader* depthReader = acq.GetDepthReader();

		int depthWidth = 512;
		int depthHeight = 424;
		// To Reserve Depth Frame Buffer
		std::vector<UINT16> depthBuffer(depthWidth * depthHeight);

		int colorWidth = 1920;
		int colorHeight = 1080;
		// To Reserve Color Frame Buffer
		std::vector<RGBQUAD> colorBuffer(colorWidth * colorHeight);

		// Acquire Latest Color Frame
		IColorFrame* pColorFrame = nullptr;
		HRESULT hResult = S_OK;
		hResult = colorReader->AcquireLatestFrame(&pColorFrame);
		if (SUCCEEDED(hResult)){
			// Retrieved Color Data
			hResult = pColorFrame->CopyConvertedFrameDataToArray(colorBuffer.size() * sizeof(RGBQUAD), reinterpret_cast<BYTE*>(&colorBuffer[0]), ColorImageFormat::ColorImageFormat_Bgra);
			if (FAILED(hResult)){
				std::cerr << "Error : IColorFrame::CopyConvertedFrameDataToArray()" << std::endl;
			}
		}
		else{ continue; }
		if (SUCCEEDED(hResult))
		{
			// conversion to mat
			Mat ris2 = Mat(colorHeight, colorWidth, CV_8UC4, &colorBuffer[0], Mat::AUTO_STEP).clone();
			cvtColor(ris2, ris2, CV_BGRA2BGR);
			colorMat = ris2.clone();
		}
		SafeRelease(pColorFrame);

		// Acquire Latest Depth Frame
		IDepthFrame* pDepthFrame = nullptr;
		hResult = depthReader->AcquireLatestFrame(&pDepthFrame);
		if (SUCCEEDED(hResult)){
			// Retrieved Depth Data
			hResult = pDepthFrame->CopyFrameDataToArray(depthBuffer.size(), &depthBuffer[0]);
			if (FAILED(hResult)){
				std::cerr << "Error : IDepthFrame::CopyFrameDataToArray()" << std::endl;
			}
		}
		else{ continue; }
		if (SUCCEEDED(hResult))
		{
			// conversion to mat
			UINT16* depthArray = new UINT16[depthHeight*depthWidth];
			copy(depthBuffer.begin(), depthBuffer.end(), depthArray);

			Mat ris2 = Mat(depthHeight, depthWidth, CV_16UC1, depthArray, Mat::AUTO_STEP).clone();
			Mat3b risDef(depthHeight, depthWidth);

			int x, y;
			for (y = 0; y<depthHeight; y++)
				for (x = 0; x<depthWidth; x++){
					risDef(y, x)[0] = (ris2.at<UINT16>(y, x) - 500) / 8;
					risDef(y, x)[1] = (ris2.at<UINT16>(y, x) - 500) / 8;
					risDef(y, x)[2] = (ris2.at<UINT16>(y, x) - 500) / 8;
				}

			depthMat = ris2.clone();
			delete[] depthArray;
		}
		SafeRelease(pDepthFrame);


		// BGD SUBTRACTION
		// Lets change some MOG2 parameters
		pMOG2.set("varThresholdGen", 625.0);
		pMOG2.set("backgroundRatio", 0.4);
		//Update the background model
		pMOG2(depthMat, fgMaskMOG2);
		// Morphology: OPEN
		int morph_size = 2;
		Mat element = getStructuringElement(MORPH_ELLIPSE, Size(4 * morph_size + 1, 2 * morph_size + 1), Point(morph_size, morph_size));
		morphologyEx(fgMaskMOG2, fgMaskMOG2, MORPH_OPEN, element);
		//		GaussianBlur(fgMaskMOG2, fgMaskMOG2, Size(3, 3), 0);
		//		dest = fgMaskMOG2.clone();
		//		bilateralFilter(fgMaskMOG2, dest, 19, 38, 9.5);
		//		medianBlur(fgMaskMOG2, fgMaskMOG2, 5);

		Mat foregroundDepthMat; //where we store the final result
		depthMat.copyTo(foregroundDepthMat, fgMaskMOG2); //filtering the original depthMat through bgdSUB mask to obtain final result

		//we have to revert to a vector to use it in a pointcloud
		std::vector<UINT16> foregroundDepthBuffer(depthMat.rows * depthMat.cols);
		foregroundDepthBuffer.assign((UINT16*) (foregroundDepthMat.datastart), (UINT16*) (foregroundDepthMat.dataend)); 
		//(debug)
		//imshow("Original Depth", depthMat);
		//imshow("foreground Depth Mat", foregroundDepthMat);
		//waitKey(30);

		// Create Point Cloud
		PointCloud<PointXYZRGB>::Ptr pointCloud(new PointCloud<PointXYZRGB>());
		pointCloud->width = static_cast<uint32_t>(depthWidth);
		pointCloud->height = static_cast<uint32_t>(depthHeight);
		pointCloud->is_dense = false;

		for (int y = 0; y < depthHeight; y++){
			for (int x = 0; x < depthWidth; x++){
				PointXYZRGB point;

				DepthSpacePoint depthSpacePoint = { static_cast<float>(x), static_cast<float>(y) };
				UINT16 depth = foregroundDepthBuffer[y * depthWidth + x];
				//TURBO
				if (depth == 0)
					continue;

				// Coordinate Mapping Depth to Color Space, and Setting PointCloud RGB
				ColorSpacePoint colorSpacePoint = { 0.0f, 0.0f };
				coordinateMapper->MapDepthPointToColorSpace(depthSpacePoint, depth, &colorSpacePoint);
				int colorX = static_cast<int>(std::floor(colorSpacePoint.X + 0.5f));
				int colorY = static_cast<int>(std::floor(colorSpacePoint.Y + 0.5f));
				if ((0 <= colorX) && (colorX < colorWidth) && (0 <= colorY) && (colorY < colorHeight)){
					RGBQUAD color = colorBuffer[colorY * colorWidth + colorX];
					point.b = color.rgbBlue;
					point.g = color.rgbGreen;
					point.r = color.rgbRed;
				}

				// Coordinate Mapping Depth to Camera Space, and Setting PointCloud XYZ
				CameraSpacePoint cameraSpacePoint = { 0.0f, 0.0f, 0.0f };
				coordinateMapper->MapDepthPointToCameraSpace(depthSpacePoint, depth, &cameraSpacePoint);
				if ((0 <= colorX) && (colorX < colorWidth) && (0 <= colorY) && (colorY < colorHeight)){
					point.x = cameraSpacePoint.X;
					point.y = cameraSpacePoint.Y;
					point.z = cameraSpacePoint.Z;
				}

				pointCloud->push_back(point);

			}
		}


		// Free memory
		vector<UINT16>().swap(depthBuffer);
		vector<UINT16>().swap(foregroundDepthBuffer);

		//crop box
		Eigen::Vector4f minPoint;
		minPoint[0] = -2.65;  // define minimum point x (R)
		minPoint[1] = -2.35;  // define minimum point y (G)
		minPoint[2] = 0;  // define minimum point z (B)
		Eigen::Vector4f maxPoint;
		maxPoint[0] = 3.65;  // define max point x 
		maxPoint[1] = 1.56;  // define max point y 
		maxPoint[2] = 2.96;  // define max point z 

		CropBox<PointXYZRGB> cropFilter;
		cropFilter.setInputCloud(pointCloud);
		cropFilter.setMin(minPoint);
		cropFilter.setMax(maxPoint);
		PointCloud<PointXYZRGB>::Ptr filteredPointCloud(new PointCloud<PointXYZRGB>);
		cropFilter.filter(*pointCloud);

		// Show Point Cloud on Cloud Viewer
		viewer.showCloud(pointCloud);		

		// Input Key ( Exit ESC key )
		if (GetKeyState(VK_ESCAPE) < 0){
			break;
		}

	}

	// End Processing

	return 0;
}

